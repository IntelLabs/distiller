# time python3 compress_classifier.py -a=mobilenet -p=50 --lr=0.001 ../../../data.imagenet/ -j=22 --resume=mobilenet_sgd_68.848.pth.tar --epochs=96 --compress=../agp-pruning//mobilenet.imagenet.schedule_agp.yaml
#
# A pretrained MobileNet (width=1) can be downloaded from: https://github.com/marvis/pytorch-mobilenet (top1: 68.848; top5: 88.740)
#
# Parameters:
# +----+--------------------------+--------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# |    | Name                     | Shape              |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
# |----+--------------------------+--------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
# |  0 | module.model.0.0.weight  | (32, 3, 3, 3)      |           864 |            864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14464 |  0.00108 |    0.06509 |
# |  1 | module.model.1.0.weight  | (32, 1, 3, 3)      |           288 |            288 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32138 |  0.01007 |    0.12923 |
# |  2 | module.model.1.3.weight  | (64, 32, 1, 1)     |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11941 |  0.00027 |    0.03629 |
# |  3 | module.model.2.0.weight  | (64, 1, 3, 3)      |           576 |            576 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15801 |  0.00543 |    0.11486 |
# |  4 | module.model.2.3.weight  | (128, 64, 1, 1)    |          8192 |           8192 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08440 | -0.00034 |    0.04182 |
# |  5 | module.model.3.0.weight  | (128, 1, 3, 3)     |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16780 |  0.00114 |    0.10551 |
# |  6 | module.model.3.3.weight  | (128, 128, 1, 1)   |         16384 |          16384 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07125 | -0.00192 |    0.04127 |
# |  7 | module.model.4.0.weight  | (128, 1, 3, 3)     |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10182 |  0.00172 |    0.08723 |
# |  8 | module.model.4.3.weight  | (256, 128, 1, 1)   |         32768 |          16384 |    0.00000 |    0.00000 | 10.15625 | 50.00000 | 12.50000 |   50.00000 | 0.05606 | -0.00004 |    0.02986 |
# |  9 | module.model.5.0.weight  | (256, 1, 3, 3)     |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12516 | -0.00287 |    0.08047 |
# | 10 | module.model.5.3.weight  | (256, 256, 1, 1)   |         65536 |          32768 |    0.00000 |    0.00000 | 12.50000 | 50.00000 | 23.04688 |   50.00000 | 0.04501 |  0.00002 |    0.02443 |
# | 11 | module.model.6.0.weight  | (256, 1, 3, 3)     |          2304 |           2304 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08024 |  0.00252 |    0.06383 |
# | 12 | module.model.6.3.weight  | (512, 256, 1, 1)   |        131072 |          65536 |    0.00000 |    0.00000 | 23.04688 | 50.00000 | 14.06250 |   50.00000 | 0.03595 | -0.00059 |    0.01904 |
# | 13 | module.model.7.0.weight  | (512, 1, 3, 3)     |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11005 | -0.00009 |    0.06821 |
# | 14 | module.model.7.3.weight  | (512, 512, 1, 1)   |        262144 |         131072 |    0.00000 |    0.00000 | 14.06250 | 50.00000 | 20.89844 |   50.00000 | 0.02978 | -0.00061 |    0.01637 |
# | 15 | module.model.8.0.weight  | (512, 1, 3, 3)     |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08257 |  0.00365 |    0.04913 |
# | 16 | module.model.8.3.weight  | (512, 512, 1, 1)   |        262144 |         131072 |    0.00000 |    0.00000 | 19.92188 | 50.00000 | 27.53906 |   50.00000 | 0.02887 | -0.00047 |    0.01543 |
# | 17 | module.model.9.0.weight  | (512, 1, 3, 3)     |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07575 |  0.00472 |    0.04201 |
# | 18 | module.model.9.3.weight  | (512, 512, 1, 1)   |        262144 |         131072 |    0.00000 |    0.00000 | 27.53906 | 50.00000 | 21.67969 |   50.00000 | 0.02959 | -0.00046 |    0.01581 |
# | 19 | module.model.10.0.weight | (512, 1, 3, 3)     |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07092 |  0.00016 |    0.04316 |
# | 20 | module.model.10.3.weight | (512, 512, 1, 1)   |        262144 |         131072 |    0.00000 |    0.00000 | 23.63281 | 50.00000 | 20.31250 |   50.00000 | 0.03127 | -0.00059 |    0.01786 |
# | 21 | module.model.11.0.weight | (512, 1, 3, 3)     |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.05727 | -0.00522 |    0.04272 |
# | 22 | module.model.11.3.weight | (512, 512, 1, 1)   |        262144 |         131072 |    0.00000 |    0.00000 | 20.50781 | 50.00000 | 17.38281 |   50.00000 | 0.03274 | -0.00043 |    0.01948 |
# | 23 | module.model.12.0.weight | (512, 1, 3, 3)     |          4608 |           4608 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.04979 | -0.00142 |    0.03969 |
# | 24 | module.model.12.3.weight | (1024, 512, 1, 1)  |        524288 |         262144 |    0.00000 |    0.00000 | 12.89062 | 50.00000 | 37.79297 |   50.00000 | 0.02520 | -0.00108 |    0.01299 |
# | 25 | module.model.13.0.weight | (1024, 1, 3, 3)    |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.02396 | -0.00950 |    0.01550 |
# | 26 | module.model.13.3.weight | (1024, 1024, 1, 1) |       1048576 |         524288 |    0.00000 |    0.00000 | 42.08984 | 50.00000 |  1.46484 |   50.00000 | 0.01811 | -0.00018 |    0.00973 |
# | 27 | module.fc.weight         | (1000, 1024)       |       1024000 |         409600 |    1.46484 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |   60.00000 | 0.05075 |  0.00271 |    0.02733 |
# | 28 | Total sparsity:          | -                  |       4209088 |        2038208 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |   51.57602 | 0.00000 |  0.00000 |    0.00000 |
# +----+--------------------------+--------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# 2018-04-21 16:19:28,225 - Total sparsity: 51.58
#
# 2018-04-21 16:19:28,225 - --- validate (epoch=199)-----------
# 2018-04-21 16:19:28,225 - 128116 samples (256 per mini-batch)
# 2018-04-21 16:19:42,090 - Epoch: [199][   50/  500]    Loss 1.495942    Top1 65.710938    Top5 84.726562
# 2018-04-21 16:19:49,138 - Epoch: [199][  100/  500]    Loss 1.490469    Top1 65.441406    Top5 84.820312
# 2018-04-21 16:19:56,590 - Epoch: [199][  150/  500]    Loss 1.492533    Top1 65.343750    Top5 84.846354
# 2018-04-21 16:20:03,476 - Epoch: [199][  200/  500]    Loss 1.493404    Top1 65.390625    Top5 84.886719
# 2018-04-21 16:20:10,929 - Epoch: [199][  250/  500]    Loss 1.491464    Top1 65.395313    Top5 84.918750
# 2018-04-21 16:20:19,233 - Epoch: [199][  300/  500]    Loss 1.488342    Top1 65.462240    Top5 84.911458
# 2018-04-21 16:20:26,250 - Epoch: [199][  350/  500]    Loss 1.491386    Top1 65.410714    Top5 84.927455
# 2018-04-21 16:20:33,847 - Epoch: [199][  400/  500]    Loss 1.486366    Top1 65.487305    Top5 84.976562
# 2018-04-21 16:20:40,802 - Epoch: [199][  450/  500]    Loss 1.485787    Top1 65.466146    Top5 84.991319
# 2018-04-21 16:20:47,634 - Epoch: [199][  500/  500]    Loss 1.485950    Top1 65.407031    Top5 84.992188
# 2018-04-21 16:20:47,675 - ==> Top1: 65.417    Top5: 84.993    Loss: 1.485
#
# 2018-04-21 16:20:47,685 - Saving checkpoint
# 2018-04-21 16:20:47,814 - --- test ---------------------
# 2018-04-21 16:20:47,815 - 50000 samples (256 per mini-batch)
# 2018-04-21 16:21:03,256 - Test: [   50/  195]    Loss 0.942188    Top1 75.156250    Top5 93.265625
# 2018-04-21 16:21:11,166 - Test: [  100/  195]    Loss 1.077203    Top1 72.500000    Top5 91.386719
# 2018-04-21 16:21:19,132 - Test: [  150/  195]    Loss 1.224955    Top1 69.708333    Top5 89.278646
# 2018-04-21 16:21:27,875 - ==> Top1: 68.808    Top5: 88.656    Loss: 1.276


version: 1
pruners:
  conv50_pruner:
    class: 'AutomatedGradualPruner'
    initial_sparsity : 0.15
    final_sparsity: 0.50
    weights: [module.model.4.3.weight, module.model.5.3.weight, module.model.6.3.weight, module.model.7.3.weight,
              module.model.8.3.weight, module.model.9.3.weight, module.model.10.3.weight, module.model.11.3.weight,
              module.model.12.3.weight, module.model.13.3.weight]

  conv60_pruner:
    class: 'AutomatedGradualPruner'
    initial_sparsity : 0.15
    final_sparsity: 0.60
    weights: [module.fc.weight]

lr_schedulers:
  pruning_lr:
    class: StepLR
    step_size: 30
    gamma: 0.10

policies:
  - pruner:
      instance_name : 'conv50_pruner'
    starting_epoch: 103
    ending_epoch: 123
    frequency: 2

  - pruner:
      instance_name : 'conv60_pruner'
    starting_epoch: 103
    ending_epoch: 123
    frequency: 2

  - lr_scheduler:
      instance_name: pruning_lr
    starting_epoch: 103
    ending_epoch: 200
    frequency: 1
