# Fine-tuning after channel regularization training (SSL) of ResNet20-CIFAR10.
# This model saves 26.6% of the original MACs, without any degradation of accuracy performance.
#
# time python3 compress_classifier.py --arch resnet20_cifar  ../data.cifar10 -p=50 --lr=0.3 --epochs=98 --compress=../ssl/ssl_channels-removal_finetuning.yaml -j=1 --deterministic --resume=../ssl/checkpoints/checkpoint_trained_channel_regularized_resnet20.pth.tar
#
# Parameters:
# +----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# |    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
# |----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
# |  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.44725 | -0.00951 |    0.31665 |
# |  1 | module.layer1.0.conv1.weight        | (11, 16, 3, 3) |          1584 |           1584 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18471 | -0.01489 |    0.12768 |
# |  2 | module.layer1.0.conv2.weight        | (16, 11, 3, 3) |          1584 |           1584 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16425 |  0.01127 |    0.11956 |
# |  3 | module.layer1.1.conv1.weight        | (8, 16, 3, 3)  |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13847 | -0.01324 |    0.08680 |
# |  4 | module.layer1.1.conv2.weight        | (16, 8, 3, 3)  |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12546 | -0.00628 |    0.07095 |
# |  5 | module.layer1.2.conv1.weight        | (8, 16, 3, 3)  |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.19293 | -0.02050 |    0.13821 |
# |  6 | module.layer1.2.conv2.weight        | (16, 8, 3, 3)  |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16046 |  0.00057 |    0.11633 |
# |  7 | module.layer2.0.conv1.weight        | (23, 16, 3, 3) |          3312 |           3312 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15364 | -0.00119 |    0.10563 |
# |  8 | module.layer2.0.conv2.weight        | (32, 23, 3, 3) |          6624 |           6624 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12141 | -0.00534 |    0.08793 |
# |  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32490 | -0.01461 |    0.21578 |
# | 10 | module.layer2.1.conv1.weight        | (18, 32, 3, 3) |          5184 |           5184 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10961 | -0.01067 |    0.07627 |
# | 11 | module.layer2.1.conv2.weight        | (32, 18, 3, 3) |          5184 |           5184 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08930 |  0.00027 |    0.06366 |
# | 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12719 | -0.01112 |    0.09889 |
# | 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11207 | -0.00326 |    0.08816 |
# | 14 | module.layer3.0.conv1.weight        | (51, 32, 3, 3) |         14688 |          14688 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11446 | -0.01245 |    0.08991 |
# | 15 | module.layer3.0.conv2.weight        | (64, 51, 3, 3) |         29376 |          29376 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10005 | -0.00226 |    0.07745 |
# | 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18169 | -0.01989 |    0.14047 |
# | 17 | module.layer3.1.conv1.weight        | (52, 64, 3, 3) |         29952 |          29952 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08737 | -0.00768 |    0.06348 |
# | 18 | module.layer3.1.conv2.weight        | (64, 52, 3, 3) |         29952 |          29952 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07228 | -0.00573 |    0.05044 |
# | 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.10261 | -0.01030 |    0.08152 |
# | 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06403 | -0.00081 |    0.04988 |
# | 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.63576 | -0.00001 |    0.53623 |
# | 22 | Total sparsity:                     | -              |        227840 |         227840 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
# +----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# Total sparsity: 0.00
#
# --- validate (epoch=277)-----------
# 5000 samples (256 per mini-batch)
# ==> Top1: 91.580    Top5: 99.860    Loss: 0.283
#
# Saving checkpoint
# --- test ---------------------
# 10000 samples (256 per mini-batch)
# ==> Top1: 91.740    Top5: 99.700    Loss: 0.332
#
#
# Log file for this run: /home/cvds_lab/nzmora/pytorch_workspace/private-distiller/examples/classifier_compression/logs/2018.04.22-002637/2018.04.22-002637.log
#
# real    18m17.976s
# user    38m22.150s
# sys     5m38.704s

lr_schedulers:
  training_lr:
    class: StepLR
    step_size: 45
    gamma: 0.10

policies:
  - lr_scheduler:
      instance_name: training_lr
    starting_epoch: 45
    ending_epoch: 300
    frequency: 1
