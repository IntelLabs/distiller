# Fine-tuning after channel regularization training (SSL) of ResNet20-CIFAR10.
# This model saves 26.6% of the original MACs, without any degradation of accuracy performance.
#
# We save the output (i.e. checkpoint.pth.tar) in ../ssl/checkpoints/checkpoint_trained_channel_regularized_resnet20_finetuned.pth.tar
#
# time python3 compress_classifier.py --arch resnet20_cifar  ../../../data.cifar10 -p=50 --lr=0.3 --epochs=98 --compress=../ssl/ssl_channels-removal_finetuning.yaml -j=1 --deterministic --resume=../ssl/checkpoints/checkpoint_trained_channel_regularized_resnet20.pth.tar
#
# Parameters:
# +----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# |    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
# |----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
# |  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.43442 | -0.00237 |    0.29579 |
# |  1 | module.layer1.0.conv1.weight        | (11, 16, 3, 3) |          1584 |           1584 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17687 | -0.01372 |    0.10154 |
# |  2 | module.layer1.0.conv2.weight        | (16, 11, 3, 3) |          1584 |           1584 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17367 |  0.00138 |    0.10962 |
# |  3 | module.layer1.1.conv1.weight        | (8, 16, 3, 3)  |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17059 | -0.02382 |    0.12258 |
# |  4 | module.layer1.1.conv2.weight        | (16, 8, 3, 3)  |          1152 |           1152 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.15539 |  0.00566 |    0.11077 |
# |  5 | module.layer1.2.conv1.weight        | (9, 16, 3, 3)  |          1296 |           1296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.18823 | -0.01534 |    0.13152 |
# |  6 | module.layer1.2.conv2.weight        | (16, 9, 3, 3)  |          1296 |           1296 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.14106 |  0.00209 |    0.09774 |
# |  7 | module.layer2.0.conv1.weight        | (22, 16, 3, 3) |          3168 |           3168 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.16194 | -0.01030 |    0.11966 |
# |  8 | module.layer2.0.conv2.weight        | (32, 22, 3, 3) |          6336 |           6336 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.12414 | -0.00590 |    0.09525 |
# |  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.32478 | -0.02495 |    0.22788 |
# | 10 | module.layer2.1.conv1.weight        | (20, 32, 3, 3) |          5760 |           5760 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09914 | -0.00858 |    0.06645 |
# | 11 | module.layer2.1.conv2.weight        | (32, 20, 3, 3) |          5760 |           5760 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07715 | -0.00281 |    0.05109 |
# | 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.13088 | -0.01235 |    0.10246 |
# | 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11205 | -0.00660 |    0.08869 |
# | 14 | module.layer3.0.conv1.weight        | (52, 32, 3, 3) |         14976 |          14976 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.11187 | -0.01344 |    0.08661 |
# | 15 | module.layer3.0.conv2.weight        | (64, 52, 3, 3) |         29952 |          29952 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09849 | -0.00310 |    0.07533 |
# | 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.17779 | -0.01871 |    0.13859 |
# | 17 | module.layer3.1.conv1.weight        | (56, 64, 3, 3) |         32256 |          32256 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.08763 | -0.00815 |    0.06467 |
# | 18 | module.layer3.1.conv2.weight        | (64, 56, 3, 3) |         32256 |          32256 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.07100 | -0.00565 |    0.05081 |
# | 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.09813 | -0.01019 |    0.07805 |
# | 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.06356 | -0.00352 |    0.04977 |
# | 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.63250 | -0.00001 |    0.53287 |
# | 22 | Total sparsity:                     | -              |        234320 |         234320 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |    0.00000 | 0.00000 |  0.00000 |    0.00000 |
# +----+-------------------------------------+----------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
# Total sparsity: 0.00
#
# --- validate (epoch=277)-----------
# 5000 samples (256 per mini-batch)
# ==> Top1: 91.100    Top5: 99.680    Loss: 0.324
#
# Saving checkpoint
# --- test ---------------------
# 10000 samples (256 per mini-batch)
# ==> Top1: 91.860    Top5: 99.760    Loss: 0.343
#
#
# real    18m24.636s
# user    40m13.991s
# sys     5m38.794s

lr_schedulers:
  training_lr:
    class: StepLR
    step_size: 45
    gamma: 0.10

policies:
  - lr_scheduler:
      instance_name: training_lr
    starting_epoch: 45
    ending_epoch: 300
    frequency: 1
