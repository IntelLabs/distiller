# We used this schedule to fine-tune a CIFAR0-ResNet20 model which had soem of its layers regularized-away with SSL (see ssl_4D-removal_training.yaml).
#
# time python3 compress_classifier.py --arch resnet20_cifar  ../../../data.cifar10 -p=50 --lr=0.1 --epochs=70 --resume=../ssl/checkpoints/checkpoint_trained_4D_regularized_5Lremoved.pth.tar --compress=../ssl/ssl_4D-removal_finetuning.yaml  -j=1 --deterministic
#
# Parameters:
#
# +----+-------------------------------------+----------------+---------------+----------------+------------+------------+-----------+-----------+-----------+------------+---------+----------+------------+
# |    | Name                                | Shape          |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |    Ch (%) |    2D (%) |    3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
# |----+-------------------------------------+----------------+---------------+----------------+------------+------------+-----------+-----------+-----------+------------+---------+----------+------------|
# |  0 | module.conv1.weight                 | (16, 3, 3, 3)  |           432 |            432 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.51103 | -0.01183 |    0.36268 |
# |  1 | module.layer1.0.conv1.weight        | (16, 16, 3, 3) |          2304 |              0 |    0.00000 |    0.00000 | 100.00000 | 100.00000 | 100.00000 |  100.00000 | 0.00000 |  0.00000 |    0.00000 |
# |  2 | module.layer1.0.conv2.weight        | (16, 16, 3, 3) |          2304 |              0 |    0.00000 |    0.00000 | 100.00000 | 100.00000 | 100.00000 |  100.00000 | 0.00000 |  0.00000 |    0.00000 |
# |  3 | module.layer1.1.conv1.weight        | (16, 16, 3, 3) |          2304 |              0 |    0.00000 |    0.00000 | 100.00000 | 100.00000 | 100.00000 |  100.00000 | 0.00000 |  0.00000 |    0.00000 |
# |  4 | module.layer1.1.conv2.weight        | (16, 16, 3, 3) |          2304 |              0 |    0.00000 |    0.00000 | 100.00000 | 100.00000 | 100.00000 |  100.00000 | 0.00000 |  0.00000 |    0.00000 |
# |  5 | module.layer1.2.conv1.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.16606 | -0.01520 |    0.09997 |
# |  6 | module.layer1.2.conv2.weight        | (16, 16, 3, 3) |          2304 |           2304 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.10640 |  0.00264 |    0.06213 |
# |  7 | module.layer2.0.conv1.weight        | (32, 16, 3, 3) |          4608 |           4608 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.16443 | -0.01366 |    0.11690 |
# |  8 | module.layer2.0.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.13711 | -0.00870 |    0.10538 |
# |  9 | module.layer2.0.downsample.0.weight | (32, 16, 1, 1) |           512 |            512 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.24764 | -0.02140 |    0.16149 |
# | 10 | module.layer2.1.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.10372 | -0.01054 |    0.07532 |
# | 11 | module.layer2.1.conv2.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.06561 |  0.00020 |    0.04614 |
# | 12 | module.layer2.2.conv1.weight        | (32, 32, 3, 3) |          9216 |           9216 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.00591 |  0.00008 |    0.00318 |
# | 13 | module.layer2.2.conv2.weight        | (32, 32, 3, 3) |          9216 |              0 |    0.00000 |    0.00000 | 100.00000 | 100.00000 | 100.00000 |  100.00000 | 0.00000 |  0.00000 |    0.00000 |
# | 14 | module.layer3.0.conv1.weight        | (64, 32, 3, 3) |         18432 |          18432 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.11329 | -0.01176 |    0.08888 |
# | 15 | module.layer3.0.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.10712 | -0.00577 |    0.08459 |
# | 16 | module.layer3.0.downsample.0.weight | (64, 32, 1, 1) |          2048 |           2048 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.14089 | -0.01544 |    0.10795 |
# | 17 | module.layer3.1.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.09711 | -0.01052 |    0.07757 |
# | 18 | module.layer3.1.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.06939 | -0.00433 |    0.05414 |
# | 19 | module.layer3.2.conv1.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.09403 | -0.01059 |    0.07475 |
# | 20 | module.layer3.2.conv2.weight        | (64, 64, 3, 3) |         36864 |          36864 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.04384 |  0.00240 |    0.03382 |
# | 21 | module.fc.weight                    | (10, 64)       |           640 |            640 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    0.00000 | 0.56451 | -0.00001 |    0.47297 |
# | 22 | Total sparsity:                     | -              |        270896 |         252464 |    0.00000 |    0.00000 |   0.00000 |   0.00000 |   0.00000 |    6.80409 | 0.00000 |  0.00000 |    0.00000 |
# +----+-------------------------------------+----------------+---------------+----------------+------------+------------+-----------+-----------+-----------+------------+---------+----------+------------+
# Total sparsity: 6.80
#
# --- validate (epoch=249)-----------
# 5000 samples (256 per mini-batch)
# ==> Top1: 90.700    Top5: 99.700    Loss: 0.341
#
# Saving checkpoint
# --- test ---------------------
# 10000 samples (256 per mini-batch)
# ==> Top1: 91.020    Top5: 99.670    Loss: 0.349
#
#
# Log file for this run: /home/cvds_lab/nzmora/pytorch_workspace/private-distiller/examples/classifier_compression/logs/2018.04.07-025916/2018.04.07-025916.log
#
# real    12m54.943s
# user    25m41.770s
# sys     3m56.544s

lr_schedulers:
  finetuning_lr:
    class: StepLR
    step_size: 25
    gamma: 0.05


policies:
  - lr_scheduler:
      instance_name: finetuning_lr
    starting_epoch: 180
    ending_epoch: 300
    frequency: 1
