{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Clipped PPO for Automated Model Compression\n",
    "\n",
    "\n",
    "Continuing on the work of [AMC](https://arxiv.org/abs/1802.03494) we replace DDPG with Clipped PPO.\n",
    "\n",
    "Results are interesting and encouraging as there is learning.  However, this is less sample-efficient compared to DDPG, and therefore takes longer.\n",
    "\n",
    "We search for a 50%-MACs-constrained (FLOPs-constrained) Plain20.  From Greedy Search algorithm we know that there exists a 50%-MACs-constrained Plain20 that can provide Top1=90%.  The current fine-tuned Plain20 model from our PPO experiments has a Top1=89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup\n",
    "\n",
    "\n",
    "### Clipped PPO configuration\n",
    "\n",
    "### Distiller Clipped PPO AMC experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook code\n",
    "\n",
    "Skip this part - it is necessary only for creating the diagrams.  You may also toggle the code-view button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off code view\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import csv\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, interact, Layout\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "\n",
    "\n",
    "#plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 7),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'xx-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    if y < 1:\n",
    "        y = 100 * y\n",
    "    s = \"{:.1f}\".format(y)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'\n",
    "    \n",
    "# Widen the cells to get entire rows in the screen.\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import json\n",
    "\n",
    "def plot_layer_compute_densities(df, idx, ax=None, color=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt\n",
    "    \n",
    "    record = df.iloc[idx]\n",
    "    net_performance = json.loads(record[\"performance\"])\n",
    "    ax.bar(range(len(net_performance)), list(net_performance.values()), color=color, align='center')\n",
    "    ax.set_title(\"Ep:{} - Top1:{:.1f}%\\nMACs:{:.1f}%\".format(record['episode'], \n",
    "                                                             record['top1'], \n",
    "                                                             record['normalized_macs']))\n",
    "    #ax.set_xticks(range(len(net_performance)), list(net_performance.keys()))\n",
    "\n",
    "\n",
    "def plot_action_history(df, idx, action_type='action_history', ax=None, color=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt\n",
    "    \n",
    "    record = df.iloc[idx]\n",
    "    layer_sparsities = json.loads(record[action_type])\n",
    "    #layer_sparsities = record[action_type]\n",
    "    #layer_sparsities = layer_sparsities[1:-1].split(\",\")\n",
    "    layer_densities = [1.- float(sparsity) for sparsity in layer_sparsities]\n",
    "    ax.bar(range(len(layer_densities)), layer_densities, color=color)\n",
    "    ax.set_title(\"Ep:{} - Top1:{:.1f}%\\nMACs:{:.1f}%\".format(record['episode'], \n",
    "                                                             record['top1'], \n",
    "                                                             record['normalized_macs']))\n",
    "\n",
    "\n",
    "\n",
    "def smooth(data, win_size):\n",
    "    if not win_size:\n",
    "        return data\n",
    "    win_size = max(0, win_size)\n",
    "    return [np.mean(data[max(0, i-win_size):i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "def plot_performance(title, dfs, alpha, window_size, top1, macs, params, reward, start=0, end=-1, plot_type='error'):\n",
    "    plot_kwargs = {\"figsize\":(15,7), \"lw\": 1, \"alpha\": alpha, \"title\": title, \"grid\": True}\n",
    "    smooth_kwargs = {\"lw\": 2 if window_size > 0 else 1, \"legend\": True, \"grid\": True}\n",
    "    \n",
    "    if not isinstance(dfs, list):\n",
    "        dfs = [dfs]\n",
    "    # Apply zoom\n",
    "    df_end = min([len(df) for df in dfs])\n",
    "    if end > 0:\n",
    "        #df_end = min(df_end, end)\n",
    "        end = min(df_end, end)\n",
    "    else:\n",
    "        end = df_end\n",
    "    print(end)\n",
    "    #dfs = [df[:df_end].copy() for df in dfs] \n",
    "    dfs = [df for df in dfs] \n",
    "    df = dfs[0]\n",
    "    left_axs, right_axs = [], []\n",
    "    \n",
    "    if macs:\n",
    "        ax = df['normalized_macs'][start:end].plot(**plot_kwargs, color=\"r\")\n",
    "        left_axs.append((ax, \"MACs\"))\n",
    "        #ax.set(xlabel=\"Episode\", ylabel=\"(%)\")\n",
    "        #ax.set_ylim([0,100])\n",
    "        df['smooth_normalized_macs'] = smooth(df['normalized_macs'], window_size)\n",
    "        df['smooth_normalized_macs'][start:end].plot(**smooth_kwargs, color=\"r\")\n",
    "\n",
    "    if top1:\n",
    "        for df in dfs:\n",
    "            df['smooth_top1'] = smooth(df['top1'], window_size)\n",
    "        \n",
    "        if len(dfs) > 1:\n",
    "            plot_kwargs['alpha'] = 1.0\n",
    "            plot_kwargs['legend'] = True\n",
    "            if plot_type == 'error':\n",
    "                top1_len = min([len(df) for df in dfs])\n",
    "                dfs = [df[:top1_len] for df in dfs]\n",
    "                dfs_top1 = [df['smooth_top1'] for df in dfs]\n",
    "                dfs_top1_dp = pd.DataFrame(dfs_top1)\n",
    "                top1_min = dfs_top1_dp.min(axis=0)\n",
    "                top1_max = dfs_top1_dp.max(axis=0)\n",
    "                top1_mean = dfs_top1_dp.mean(axis=0)\n",
    "                \n",
    "                display_mean = False\n",
    "                if display_mean:\n",
    "                    ax = top1_mean.plot(**plot_kwargs, color=\"b\")\n",
    "                \n",
    "                for p in dfs_top1:\n",
    "                    ax = p[start:end].plot(**plot_kwargs)\n",
    "                if display_mean:\n",
    "                    ax.legend(['mean'] + [str(i+1) for i in range(len(dfs_top1))])\n",
    "                else:\n",
    "                    ax.legend([str(i+1) for i in range(len(dfs_top1))])\n",
    "                ax.set(xlabel=\"Episode\", ylabel=\"(%)\")            \n",
    "                ax.fill_between(range(len(top1_min)), top1_max, top1_min, color=\"b\", alpha=0.3)\n",
    "\n",
    "                left_axs.append((ax, \"Top1\"))\n",
    "            else:\n",
    "                assert plot_type == 'compare'\n",
    "                dfs_top1 = [df['smooth_top1'] for df in dfs]\n",
    "                for p in dfs_top1:\n",
    "                    #ax = p[start:end].plot(**plot_kwargs)\n",
    "                    ax = p[start:].plot(**plot_kwargs)\n",
    "                ax.legend([str(i+1) for i in range(len(dfs_top1))])\n",
    "                left_axs.append((ax, \"Top1\"))\n",
    "        else:\n",
    "            ax = df['top1'][start:end].plot(**plot_kwargs, color=\"b\")\n",
    "            left_axs.append((ax, \"Top1\"))\n",
    "            #ax.set(xlabel=\"Episode\", ylabel=\"(%)\")\n",
    "            df['smooth_top1'][start:end].plot(**smooth_kwargs, color=\"b\")\n",
    "            \n",
    "    if params:\n",
    "        ax = df['normalized_nnz'][start:end].plot(**plot_kwargs, color=\"black\")\n",
    "        ax.set(xlabel=\"Episode\", ylabel=\"(%)\")\n",
    "        df['smooth_normalized_nnz'] = smooth(df['normalized_nnz'], window_size)\n",
    "        df['smooth_normalized_nnz'][start:end].plot(**smooth_kwargs, color=\"black\")        \n",
    "\n",
    "    if reward:\n",
    "        ax = df['reward'][start:end].plot(**plot_kwargs, secondary_y=True, color=\"g\")\n",
    "        ax.set(xlabel=\"Episode\", ylabel=\"Reward\")\n",
    "        df['smooth_reward'] = smooth(df['reward'], window_size)\n",
    "        df['smooth_reward'][start:end].plot(**smooth_kwargs, secondary_y=True, color=\"g\")    \n",
    "    #ax.set_ylim([0,100])\n",
    "    #ax.grid(True, which='minor', axis='x', alpha=0.3)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    \n",
    "    # The left axis might contain multiple ylabels\n",
    "    if left_axs:\n",
    "        # Pick an arbitrary axis \n",
    "        ax = left_axs[0][0]\n",
    "        # Collect all of the labels\n",
    "        ylabel = \" / \".join([ax[1] for ax in left_axs]) #left_axs[0][1]\n",
    "        ax.set(ylabel=ylabel)\n",
    "\n",
    "\n",
    "        \n",
    "def plot_2d_embeddings(top1, normalized_macs):\n",
    "    plt.figure(figsize=(15,7))        \n",
    "    plt.title('Projection of Discovered Networks ({})'.format(len(top1)))     \n",
    "    plt.xlabel('Normalized MACs')\n",
    "    plt.ylabel('Top1 Accuracy')\n",
    "\n",
    "    # Create the formatter using the function to_percent. This multiplies all the\n",
    "    # default labels by 100, making them all percentages\n",
    "    formatter = FuncFormatter(to_percent)\n",
    "\n",
    "    # Set the formatter\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    # Use color gradients to show the \"age\" of the network:\n",
    "    # Lighter networks were discovered earlier than darker ones.\n",
    "    color_grad = [str(1-i/len(top1)) for i in range(len(top1))]\n",
    "    plt.scatter(normalized_macs, top1, color=color_grad, s=80, edgecolors='gray');\n",
    "\n",
    "    \n",
    "INTERVAL = 30 # Animation speed\n",
    "WINDOW = 20\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'darkred',\n",
    "        'weight': 'normal',\n",
    "        'alpha': 0.50,\n",
    "        'size': 32,\n",
    "        }\n",
    "\n",
    "# Based on these two helpful example code: \n",
    "# https://stackoverflow.com/questions/9401658/how-to-animate-a-scatter-plot\n",
    "# http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-notebooks/.\n",
    "# Specifically, the use of IPython.display is missing from the first example, but most of the animation code\n",
    "# leverages code from there.\n",
    "class AnimatedScatter(object):\n",
    "    \"\"\"An animated scatter plot using matplotlib.animations.FuncAnimation.\"\"\"\n",
    "    def __init__(self, xdata, ydata):\n",
    "        assert len(xdata) == len(ydata)\n",
    "        self.numpoints = len(xdata)\n",
    "        self.xdata = xdata\n",
    "        self.ydata = ydata\n",
    "        self.stream = self.data_stream()\n",
    "\n",
    "        # Setup the figure and axes...\n",
    "        self.fig, self.ax = plt.subplots(figsize=(15,7))\n",
    "        # Then setup FuncAnimation.\n",
    "        self.ani = animation.FuncAnimation(self.fig, self.update, interval=INTERVAL,\n",
    "                                           frames=self.numpoints-2, \n",
    "                                           init_func=self.setup_plot, blit=True)\n",
    "\n",
    "    def setup_plot(self):\n",
    "        \"\"\"Initialize drawing of the scatter plot.\"\"\"\n",
    "        x, y, s, c = next(self.stream)\n",
    "        #self.annot = self.ax.annotate(\"txt\", (10, 10))\n",
    "        self.scat = self.ax.scatter(x, y, c=c, s=s, animated=False)\n",
    "        self.scat.set_edgecolors('gray')\n",
    "        self.scat.set_cmap('gray')\n",
    "        self.width = max(self.xdata) - min(self.xdata) + 4\n",
    "        self.height = max(self.ydata) - min(self.ydata) + 4\n",
    "        self.ax.axis([min(self.xdata)-2, max(self.xdata)+2, \n",
    "                      min(self.ydata)-2, max(self.ydata)+2])\n",
    "        \n",
    "        self.annot = self.ax.text(min(self.xdata) + self.width/2, \n",
    "                     min(self.xdata) + self.height/2, \n",
    "                     \"\", fontdict=font)\n",
    "        # For FuncAnimation's sake, we need to return the artist we'll be using\n",
    "        # Note that it expects a sequence of artists, thus the trailing comma.\n",
    "        return self.scat, \n",
    "\n",
    "    def data_stream(self):\n",
    "        numpoints = 0#len(self.xdata)\n",
    "        colors = []\n",
    "        xxx = 0\n",
    "        while True:\n",
    "            numpoints += 1\n",
    "            win_len = min(WINDOW, numpoints)\n",
    "            data = np.ndarray((4, win_len))\n",
    "            start = max(0,numpoints-WINDOW-1)\n",
    "            data[0, :] = self.xdata[start:start+win_len]\n",
    "            data[1, :] = self.ydata[start:start+win_len]\n",
    "            data[2, :] = [70] * win_len  # point size\n",
    "            #data[3, :] = [np.random.random() for p in range(numpoints)]  # color\n",
    "            # The color of the points is a gradient with larger values for \"younger\" points.\n",
    "            # At each new frame we show one more point, and \"age\" each existing point by incrementaly  \n",
    "            # reducing its color gradient.\n",
    "            data[3, :] = [(1-i/(win_len+1)) for i in range(win_len)] \n",
    "            yield data\n",
    "\n",
    "    def update(self, i):      \n",
    "        \"\"\"Update the scatter plot.\"\"\"\n",
    "        data = next(self.stream)\n",
    "        self.annot.set_text(i)\n",
    "        i = i % len(data)\n",
    "            \n",
    "        # Set x and y data\n",
    "        xy = [(data[0,i], data[1,i]) for i in range(len(data[0,:]))]\n",
    "        self.scat.set_offsets(xy)\n",
    "        \n",
    "        # Set colors\n",
    "        self.scat.set_array(data[3])\n",
    "        \n",
    "        # We need to return the updated artist for FuncAnimation to draw..\n",
    "        # Note that it expects a sequence of artists, thus the trailing comma.\n",
    "        return self.scat, self.annot\n",
    "\n",
    "    def show(self):\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results\n",
    "\n",
    "Below I present the results of a single execution.  There is a substantial variance between the experiment executions, but most conclude similarly to this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the results log files\n",
    "\n",
    "The code below reads the log file of your selected experiment.  To change the path to the file you will need to open the code cell and change its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "fpath = \"../classifier_compression/logs/{}/amc.csv\"\n",
    "\n",
    "fname1= fpath.format(\"mobilenet_v1_71.2_private_l2-norm_50-pts___2019.07.04-000305/\")\n",
    "\n",
    "df = pd.read_csv(fname)\n",
    "df1, df2, df3 = pd.read_csv(fname1), pd.read_csv(fname2), pd.read_csv(fname3)\n",
    "df4 = pd.read_csv(fname4)\n",
    "#df[600:]\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot experiment performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,7))\n",
    "#print(plt.style.available)\n",
    "#plt.style.use('seaborn-paper')\n",
    "        \n",
    "@interact(window_size=(0,50,5), top1=True, macs=True, params=False, reward=True)\n",
    "def plot_performance_proxy(window_size=10, top1=True, macs=True, params=False, reward=True):\n",
    "    plot_performance(\"Training Data\", df, 0.15, window_size, top1, macs, params, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1,df2, df3]\n",
    "df_len = min([len(df) for df in dfs])\n",
    "\n",
    "@interact(window_size=(0,50,5), top1=True, macs=True, params=False, reward=True, zoom=(0,df_len,1))\n",
    "def plot_experiment_comparison(window_size=10, zoom=0):\n",
    "    start = 0\n",
    "    end = zoom if zoom > 0 else 0\n",
    "    plot_performance(\"Compare Experiments (Top1)\", dfs, \n",
    "                     0.15, window_size, True, False, False, False, start, end, plot_type='compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(window_size=(0,50,5), top1=True, macs=True, params=False, reward=True)\n",
    "def plot_experiment_comparison(window_size=10):\n",
    "    dfs = [df1,df2, df3]\n",
    "    plot_performance(\"Compare Experiments (Top1)\", dfs, \n",
    "                     0.15, window_size, True, False, False, False, plot_type='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sample some networks\n",
    "\n",
    "Let's look at the networks with the best top1 accuracy, and see if they share geometrical attributes.\n",
    "\n",
    "We sort the discovered networks by their Top1 accuracy and display the density of each layer in the networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_sorted_df = df1.sort_values(by=['reward'], ascending=False)\n",
    "top1_sorted_df\n",
    "nrows = 2; ncols = 4\n",
    "f, axarr = plt.subplots(nrows, ncols, figsize=(15,7))\n",
    "for i in range(0, nrows * ncols):\n",
    "    plot_layer_compute_densities(top1_sorted_df, i, ax=axarr[i//ncols, i%ncols], color='g')\n",
    "    # Fine-tune figure; make subplots farther from each other.\n",
    "    f.subplots_adjust(hspace=0.6, wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the actions the networks experienced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#top1_sorted_df = df.sort_values(by=['reward'], ascending=False)\n",
    "nrows = 2; ncols = 4\n",
    "f, axarr = plt.subplots(nrows, ncols, figsize=(15,7))\n",
    "for i in range(0, nrows * ncols):\n",
    "    plot_action_history(top1_sorted_df, i, ax=axarr[i//ncols, i%ncols], color='g')\n",
    "    # Fine-tune figure; make subplots farther from each other.\n",
    "    f.subplots_adjust(hspace=0.6, wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-layer filter density distribution - top 10% networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10pct = top1_sorted_df[:int(len(df.index) * 0.1)]\n",
    "#top10pct = df[int(len(df.index) * 0.95):]\n",
    "\n",
    "layer_densities_list = []\n",
    "for index, row in top10pct.iterrows():\n",
    "    #layer_sparsities = row['action_history']\n",
    "    layer_sparsities = json.loads(row['action_history'])\n",
    "    #layer_sparsities = layer_sparsities[1:-1].split(\",\")  # convert from string to list\n",
    "    layer_densities = [1. - float(sparsity) for sparsity in layer_sparsities]\n",
    "    layer_densities_list.append(layer_densities)\n",
    "\n",
    "layer_densities = np.array(layer_densities_list)\n",
    "mean = layer_densities.mean(axis=0)\n",
    "std = layer_densities.std(axis=0)\n",
    "\n",
    "\n",
    "# Draw the bar diagram of the layer densities\n",
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "ax.set_title(\"Best sampled models (90th percentile)\\nPer-layer filter density (mean and std)\")\n",
    "xpos = [i for i in range(len(mean))]\n",
    "ax.bar(xpos, mean, yerr=std, capsize=10, alpha=0.5, ecolor='black')\n",
    "ax.set_ylabel('Filter density')\n",
    "ax.set_xticks(xpos)\n",
    "#ax.set_xticklabels(layer_names)\n",
    "ax.yaxis.grid(True)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2D embeddings\n",
    "\n",
    "Let's create an embedding of the networks AMC discovers over the course of each experiment session.  Each network is projected onto a 2D plane mapping the Top1 accuracy versus the compute budget, and is represented by a small circle. I used gradient-color-coding to show the relative phase where each network is discovered.  Lighter circles are networks discovered early in the search, darker networks are discovered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top1 = df['top1']\n",
    "normalized_macs = df['normalized_macs']\n",
    "plot_2d_embeddings(top1, normalized_macs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = AnimatedScatter(normalized_macs, top1)\n",
    "plt.title('Projection of Discovered Networks ({})'.format(len(top1)))  \n",
    "plt.xlabel('Normalized MACs')\n",
    "plt.ylabel('Top1 Accuracy')\n",
    "#a.ani.save('amc_vgg16.mp4', fps=10, dpi=80) #Frame per second controls speed, dpi controls the quality \n",
    "rc('animation', html='html5')\n",
    "a.ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram of the actions\n",
    "\n",
    "We want to look at the distribution of the sampled agent actions (```agent_actions``` below), to make sure they are not skewed or biased.\n",
    "\n",
    "We also want to compare these actions to the actions the environment actually acts on (these we call ```env_actions``` below).  The natural PPO action-space is (-inf, inf) so the environment needs to scale and shift the agent actions to fit into the \"real\" action-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_actions(df, action_type='action_history'):\n",
    "    actions = []\n",
    "    for index, record in df.iterrows():\n",
    "        #layer_sparsities = record[action_type]\n",
    "        #layer_sparsities = layer_sparsities[1:-1].split(\",\")\n",
    "        layer_sparsities = json.loads(record[action_type])\n",
    "        layer_sparsities = [float(sparsity) for sparsity in layer_sparsities]\n",
    "        actions.extend(layer_sparsities)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_actions = get_all_actions(df, action_type='agent_action_history')\n",
    "env_actions = get_all_actions(df, action_type='action_history')\n",
    "print(len(agent_actions))\n",
    "\n",
    "plt.figure(figsize=[15,7.5])\n",
    "plt.hist(agent_actions, histtype='step', bins=100, label='agent_actions (u={:.2f} std={:.2f})'.format(\n",
    "                                                                                        np.mean(agent_actions),\n",
    "                                                                                        np.std(agent_actions)));\n",
    "plt.hist(env_actions, histtype='step', bins=100, label='env_actions (u={:.2f} std={:.2f})'.format(\n",
    "                                                                                        np.mean(env_actions),\n",
    "                                                                                        np.std(env_actions)));\n",
    "\n",
    "plt.title('Action histogram (actions as seen by the environment)')\n",
    "plt.legend()\n",
    "plt.xlabel('Action value')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
